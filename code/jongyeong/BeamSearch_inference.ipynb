{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8cc969c-5994-43aa-b23f-d89a95920cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from train import id_to_string\n",
    "from metrics import word_error_rate, sentence_acc\n",
    "from checkpoint import load_checkpoint\n",
    "from torchvision import transforms\n",
    "from dataset import LoadEvalDataset, collate_eval_batch, START, PAD\n",
    "from flags import Flags\n",
    "from utils import get_network, get_optimizer\n",
    "import csv\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6f022cc-8070-4a30-8989-50c9cf28ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "import math\n",
    "import operator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from queue import PriorityQueue\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f50db8c-df07-4416-990c-07877e9479d1",
   "metadata": {},
   "source": [
    "- \"--checkpoint\" 에 불러올 .pth 파일 주소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27a55e63-8034-44d6-8899-1172b3daf7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "        \"--checkpoint\",\n",
    "        dest=\"checkpoint\",\n",
    "        default=\"./log/satrn_adaptive/checkpoints/0050.pth\",\n",
    "        type=str,\n",
    "        help=\"Path of checkpoint file\",\n",
    ")\n",
    "parser.add_argument(\n",
    "        \"--max_sequence\",\n",
    "        dest=\"max_sequence\",\n",
    "        default=20,\n",
    "        type=int,\n",
    "        help=\"maximun sequence when doing inference\",\n",
    ")\n",
    "parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        dest=\"batch_size\",\n",
    "        default=8,\n",
    "        type=int,\n",
    "        help=\"batch size when doing inference\",\n",
    ")\n",
    "\n",
    "eval_dir = os.environ.get('SM_CHANNEL_EVAL', '/opt/ml/input/data/')\n",
    "file_path = os.path.join(eval_dir, 'eval_dataset/input.txt')\n",
    "parser.add_argument(\n",
    "        \"--file_path\",\n",
    "        dest=\"file_path\",\n",
    "        default=file_path,\n",
    "        type=str,\n",
    "        help=\"file path when doing inference\",\n",
    ")\n",
    "\n",
    "output_dir = os.environ.get('SM_OUTPUT_DATA_DIR', 'submit')\n",
    "parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        dest=\"output_dir\",\n",
    "        default=output_dir,\n",
    "        type=str,\n",
    "        help=\"output directory\",\n",
    ")\n",
    "\n",
    "parser = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8c97ec-bb3b-48c8-8253-87ebd0648cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "checkpoint = load_checkpoint(parser.checkpoint, cuda=is_cuda)\n",
    "options = Flags(checkpoint[\"configs\"]).get()\n",
    "torch.manual_seed(options.seed)\n",
    "random.seed(options.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "763492f1-025d-4e5b-9947-0082d40a504e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Running SATRN on device cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hardware = \"cuda\" if is_cuda else \"cpu\"\n",
    "device = torch.device(hardware)\n",
    "print(\"--------------------------------\")\n",
    "print(\"Running {} on device {}\\n\".format(options.network, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d49c2b9-c704-4a61-b85d-c0b999cb76ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Checkpoint\n",
      " Resuming from epoch : 50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = checkpoint[\"model\"]\n",
    "if model_checkpoint:\n",
    "    print(\n",
    "            \"[+] Checkpoint\\n\",\n",
    "            \"Resuming from epoch : {}\\n\".format(checkpoint[\"epoch\"]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe1656b-7cf5-423f-bac9-e05dc7e62e64",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45f3a96a-388c-442d-b84e-7a97b728d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((options.input_size.height, options.input_size.width)),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbbbf11f-51aa-48af-a837-490ce58eb027",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_gt = \"\\sin \" * parser.max_sequence  # set maximum inference sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12c0db8f-248e-4917-96c1-f5e38f410efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.path.dirname(parser.file_path), \"images\")\n",
    "with open(parser.file_path, \"r\") as fd:\n",
    "    reader = csv.reader(fd, delimiter=\"\\t\")\n",
    "    data = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc9094f7-e7b7-4ea7-96ce-79cb95f9686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [[os.path.join(root, x[0]), x[0], dummy_gt] for x in data]\n",
    "test_dataset = LoadEvalDataset(\n",
    "        test_data, checkpoint[\"token_to_id\"], checkpoint[\"id_to_token\"], crop=False, transform=transformed,\n",
    "        rgb=options.data.rgb\n",
    "    )\n",
    "test_data_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=parser.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=options.num_workers,\n",
    "        collate_fn=collate_eval_batch,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e29f4317-0dc9-4cbc-bdb9-7442acbd9bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Data\n",
      " The number of test samples : 32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "        \"[+] Data\\n\",\n",
    "        \"The number of test samples : {}\\n\".format(len(test_dataset)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ad6ab8-dc19-4587-9715-6de40e7afbc0",
   "metadata": {},
   "source": [
    "## Get Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c86a0b5-f28a-4363-b276-87688fef9ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = get_network(\n",
    "        options.network,\n",
    "        options,\n",
    "        model_checkpoint,\n",
    "        device,\n",
    "        test_dataset,\n",
    "    )\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6bd6e3f-7349-42f3-af55-0b14c48766a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.encoder\n",
    "embedding = model.decoder.embedding\n",
    "pos_encoder = model.decoder.pos_encoder\n",
    "attention_layers = model.decoder.attention_layers\n",
    "generator = model.decoder.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1ee24d1-e163-47ff-b040-69ecee5fe02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_id = test_dataset.token_to_id['<SOS>']\n",
    "pad_id = test_dataset.token_to_id['<PAD>']\n",
    "layer_num = len(model.decoder.attention_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3625b72-aca6-4bee-8f6a-54c22a02271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_mask(text):\n",
    "        pad_mask = text == pad_id\n",
    "        pad_mask[:, 0] = False\n",
    "        pad_mask = pad_mask.unsqueeze(1)\n",
    "\n",
    "        return pad_mask\n",
    "\n",
    "def order_mask(length):\n",
    "        order_mask = torch.triu(torch.ones(length, length), diagonal=1).bool()\n",
    "        order_mask = order_mask.unsqueeze(0).to(device)\n",
    "        return order_mask\n",
    "\n",
    "def text_embedding(texts):\n",
    "        tgt = embedding(texts)\n",
    "        tgt *= math.sqrt(tgt.size(2))\n",
    "\n",
    "        return tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41a64aa7-29a5-4c29-a91f-8e5d018945fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearchNode(object):\n",
    "    def __init__(self, src_batch, previousNode, target_batch, features, logProb, length):\n",
    "        self.src_batch = src_batch\n",
    "        self.prevNode = previousNode\n",
    "        self.target_batch = target_batch\n",
    "        self.features = features\n",
    "        self.logp = logProb\n",
    "        self.leng = length\n",
    "        \n",
    "    def eval(self, alpha = 1.0):\n",
    "        reward = 0\n",
    "        \n",
    "        return self.logp / float(self.leng - 1 +1e6) + alpha * reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157bd1b-1863-4cc6-83d2-f82c7d756e0f",
   "metadata": {},
   "source": [
    "## Beam Search decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9a8bb03-22d4-464c-900b-d899a87e3e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f69a5b5f-3470-40e2-923e-dce4bca62e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:35<00:00,  8.97s/it]\n"
     ]
    }
   ],
   "source": [
    "for d in tqdm(test_data_loader):\n",
    "    input = d[\"image\"].to(device)\n",
    "    expected = d[\"truth\"][\"encoded\"].to(device)\n",
    "    \n",
    "    src = encoder(input)\n",
    "    text = expected[:, :-1]\n",
    "    is_train = False\n",
    "    batch_max_length = 230\n",
    "    teacher_forcing_ratio = 0\n",
    "    \n",
    "    beam_width = 5\n",
    "    topk = 1  # how many sentence do you want to generate\n",
    "    decoded_batch = []\n",
    "    \n",
    "    for idx in range(src.size(0)):\n",
    "        num_steps = batch_max_length - 1\n",
    "        target = torch.LongTensor(src.size(0)).fill_(st_id).to(device) # [START] token\n",
    "        features = [None] * layer_num\n",
    "\n",
    "        target_batch = target[idx].unsqueeze(-1)\n",
    "        target_batch = target_batch.unsqueeze(-1)\n",
    "        src_batch = src[idx,:,:].unsqueeze(0)\n",
    "\n",
    "        endnodes = []\n",
    "        number_required = 5\n",
    "\n",
    "        node = BeamSearchNode(src_batch, None, target_batch, features, 0, 1)\n",
    "        nodes = PriorityQueue()\n",
    "\n",
    "        nodes.put((-node.eval(), node))\n",
    "        flag = 0\n",
    "\n",
    "        # each step \n",
    "        for t in range(num_steps):        \n",
    "            if flag == 1:\n",
    "                break\n",
    "            nextnodes = []\n",
    "\n",
    "            # ecah beam search candidate\n",
    "            while nodes.queue != []:\n",
    "\n",
    "                score, n = nodes.get()\n",
    "                target_batch = n.target_batch\n",
    "                src_batch = n.src_batch\n",
    "                if n.features[0] != None:\n",
    "                    features = []\n",
    "                    for i in range(len(n.features)):\n",
    "                        with torch.no_grad():\n",
    "                            features.append(copy.deepcopy(n.features[i].detach()))\n",
    "                else:\n",
    "                    features = n.features\n",
    "\n",
    "                tgt = text_embedding(target_batch)\n",
    "                tgt = pos_encoder(tgt, point=t)\n",
    "                tgt_mask = order_mask(t + 1)\n",
    "                tgt_mask = tgt_mask[:, -1].unsqueeze(1) \n",
    "                        \n",
    "                if n.target_batch.item() == 1 and n.prevNode != None:\n",
    "                    endnodes.append((score, n))\n",
    "                    # if we reached maximum # of sentences required\n",
    "                    if len(endnodes) >= number_required:\n",
    "                        flag = 1\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "                # each attention layer \n",
    "                for l, layer in enumerate(attention_layers):\n",
    "                    tgt = layer(tgt, features[l], src_batch, tgt_mask)\n",
    "                    features[l] = (tgt if features[l] == None else torch.cat([features[l], tgt], 1))\n",
    "\n",
    "                _out = generator(tgt)\n",
    "                log_prob, indexes = torch.topk(_out, beam_width)\n",
    "\n",
    "                for new_k in range(beam_width):\n",
    "                    decoded_t = indexes[0][0][new_k].view(1, -1)\n",
    "                    log_p = log_prob[0][0][new_k].item()\n",
    "\n",
    "                    node = BeamSearchNode(src_batch, n, decoded_t, features, n.logp + log_p, n.leng + 1)\n",
    "                    score = -node.eval()\n",
    "                    nextnodes.append((score, node))\n",
    "            \n",
    "            if flag == 0:\n",
    "                #sorting nextnode\n",
    "                sorted(nextnodes, key=operator.itemgetter(0))\n",
    "                # put them into queue\n",
    "                for i in range(beam_width):\n",
    "                    score, nn = nextnodes[i]\n",
    "                    nodes.put((score, nn))\n",
    "\n",
    "                        \n",
    "            \n",
    "        if len(endnodes) == 0:\n",
    "            endnodes = [nodes.get() for _ in range(1)]\n",
    "            \n",
    "            \n",
    "        utterances = []\n",
    "        for score, n in sorted(endnodes, key=operator.itemgetter(0)):\n",
    "            utterance = []\n",
    "            utterance.append(n.target_batch)\n",
    "            # back trace\n",
    "            while n.prevNode != None:\n",
    "                n = n.prevNode\n",
    "                utterance.append(n.target_batch)\n",
    "\n",
    "            del utterance[-1]\n",
    "            utterance = utterance[::-1]\n",
    "            utterances.append(utterance)\n",
    "            break\n",
    "\n",
    "        seq_len = len(utterances[0])\n",
    "        if num_steps - seq_len > 0:\n",
    "            for i in range(num_steps - seq_len):\n",
    "                utterances[0].append(torch.LongTensor(1).fill_(2).to(device))\n",
    "        decoded_batch.append(utterances)\n",
    "            \n",
    "\n",
    "            \n",
    "    sequence = torch.tensor(decoded_batch)\n",
    "    sequence = sequence.squeeze(1)\n",
    "    sequence_str = id_to_string(sequence, test_data_loader, do_eval=1)\n",
    "    for path, predicted in zip(d[\"file_path\"], sequence_str):\n",
    "            results.append((path, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ab85a284-6d4c-4dcd-b364-bae22a2608e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(parser.output_dir, exist_ok=True)\n",
    "with open(os.path.join(parser.output_dir, \"output1.csv\"), \"w\") as w:\n",
    "    for path, predicted in results:\n",
    "        w.write(path + \"\\t\" + predicted + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad639d91-ef73-48ef-8ed8-e99e95096149",
   "metadata": {},
   "source": [
    "- PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ecdd843f-b2e1-44c7-9e9e-7a37d3cb5455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('train_00000.jpg', '4 \\\\times 7 = 2 8 '),\n",
       " ('train_00001.jpg', 'a ^ { x } > q '),\n",
       " ('train_00002.jpg', '8 \\\\times 9 '),\n",
       " ('train_00003.jpg',\n",
       "  '\\\\sum _ { k = 1 } ^ { n - 1 } b _ { k } = a _ { n } - a _ { 1 } '),\n",
       " ('train_00004.jpg', 'I = d q / d t t '),\n",
       " ('train_00005.jpg', '\\\\sum \\\\overrightarrow { F } _ { e x t } = d d '),\n",
       " ('train_00006.jpg', 'i ^ { 2 } = - 1 \\\\left( i = \\\\sqrt { - 1 } \\\\right) '),\n",
       " ('train_00007.jpg', '7 \\\\times 9 = 4 9 9 '),\n",
       " ('train_00008.jpg',\n",
       "  'F \\\\left( 0 , \\\\sqrt { a ^ { 2 } + b ^ { 2 } } \\\\right) \\\\left( 0 , - \\\\sqrt { a ^ { 2 } + b ^ { 2 } } \\\\right) '),\n",
       " ('train_00009.jpg', '\\\\left( a - 2 \\\\right) \\\\left( a - 3 \\\\right) = 0 '),\n",
       " ('train_00010.jpg', '\\\\therefore b = - 9 9 '),\n",
       " ('train_00011.jpg', '2 2 + 7 - 1 2 = '),\n",
       " ('train_00012.jpg', '7 \\\\div 4 '),\n",
       " ('train_00013.jpg', 'f \\\\left( x \\\\right) = 4 x ^ { 3 '),\n",
       " ('train_00014.jpg',\n",
       "  'M P _ { l } = \\\\lim _ { \\\\Delta l \\\\to 0 } \\\\frac { g \\\\left( l + \\\\Delta l - g l \\\\right) \\\\right) \\\\right) } } } = = \\\\frac { d { d } } } } '),\n",
       " ('train_00015.jpg', '\\\\sum F _ { n } = a a { { } } '),\n",
       " ('train_00016.jpg',\n",
       "  '= \\\\frac { \\\\left( n + 2 \\\\right) \\\\left( n + 1 \\\\right) } { 2 } = 7 8 = 2 \\\\times 9 9 = 2 \\\\times 3 \\\\times 3 7 '),\n",
       " ('train_00017.jpg', '= h \\\\left( a \\\\right) '),\n",
       " ('train_00018.jpg',\n",
       "  '1 0 4 \\\\times 9 8 = \\\\left( 1 0 0 + 4 \\\\right) \\\\left( 1 0 0 - 2 \\\\right) '),\n",
       " ('train_00019.jpg', 'a _ { n } = a _ { 1 } r ^ { n - 1 } '),\n",
       " ('train_00020.jpg', 'x = - 2 '),\n",
       " ('train_00021.jpg', '= 3 x \\\\left( x ^ { 2 } + 1 \\\\right) '),\n",
       " ('train_00022.jpg', '1 8 4 - \\\\left( 8 9 + 8 8 \\\\right) = 7 '),\n",
       " ('train_00023.jpg', 't = - 1 '),\n",
       " ('train_00024.jpg',\n",
       "  '\\\\left( 1 2 x - 1 6 \\\\right) \\\\times \\\\left( - \\\\frac { 3 } { 4 } \\\\right) = 1 2 x \\\\times \\\\left( - \\\\frac { 3 } { 4 } \\\\right) '),\n",
       " ('train_00025.jpg', '\\\\frac { 1 6 } { 2 7 } \\\\div \\\\frac { 2 } { 2 7 } = '),\n",
       " ('train_00026.jpg', 'x < 4 . '),\n",
       " ('train_00027.jpg',\n",
       "  '= x \\\\left( x - 1 \\\\right) \\\\cdot \\\\left( x - y \\\\right) ! '),\n",
       " ('train_00028.jpg', '3 6 . 4 8 \\\\div 4 . 5 6 '),\n",
       " ('train_00029.jpg',\n",
       "  'a _ { 2 } = \\\\sqrt { { { { { { { { { { { { { { { { { { { { { . . . . . . . . . . . . 2 } } } } } } } } } } } '),\n",
       " ('train_00030.jpg',\n",
       "  '\\\\cap A \\\\cap A \\\\cap B \\\\right) \\\\frac \\\\frac { 1 } { } } { { { } } } } } } } } } } A A A C '),\n",
       " ('train_00031.jpg',\n",
       "  '= \\\\frac { - b ^ { \\\\prime } \\\\pm \\\\sqrt { b ^ { \\\\prime - a c } } } { a ')]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828c2323-de9d-4923-ad18-38dc696b5245",
   "metadata": {},
   "source": [
    "- G.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e6b1794f-c9bb-47c7-aedf-e9d3b803107f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['train_00000.jpg', '4 \\\\times 7 = 2 8'],\n",
       " ['train_00001.jpg', 'a ^ { x } > q'],\n",
       " ['train_00002.jpg', '8 \\\\times 9'],\n",
       " ['train_00003.jpg',\n",
       "  '\\\\sum _ { k = 1 } ^ { n - 1 } b _ { k } = a _ { n } - a _ { 1 }'],\n",
       " ['train_00004.jpg', 'I = d q / d t'],\n",
       " ['train_00005.jpg', '\\\\sum \\\\overrightarrow { F } _ { e x t } = d'],\n",
       " ['train_00006.jpg', 'i ^ { 2 } = - 1 \\\\left( i = \\\\sqrt { - 1 } \\\\right)'],\n",
       " ['train_00007.jpg', '7 \\\\times 9 = 4 9'],\n",
       " ['train_00008.jpg',\n",
       "  'F \\\\left( 0 , \\\\sqrt { a ^ { 2 } + b ^ { 2 } } \\\\right) , \\\\left( 0 , - \\\\sqrt { a ^ { 2 } + b ^ { 2 } } \\\\right)'],\n",
       " ['train_00009.jpg', '\\\\left( a - 2 \\\\right) \\\\left( a - 3 \\\\right) = 0'],\n",
       " ['train_00010.jpg', '\\\\therefore b = - 9'],\n",
       " ['train_00011.jpg', '2 2 + 7 - 1 2 ='],\n",
       " ['train_00012.jpg', '7 \\\\div 4'],\n",
       " ['train_00013.jpg', 'f \\\\left( x \\\\right) = 4 x ^ { 3 }'],\n",
       " ['train_00014.jpg',\n",
       "  'M P _ { e } = \\\\lim _ { \\\\Delta l \\\\to 0 } \\\\frac { g \\\\left( l + \\\\Delta l \\\\right) - g \\\\left( l \\\\right) } { \\\\Delta l } = \\\\frac { d g } { d l }'],\n",
       " ['train_00015.jpg', '\\\\sum F _ { \\\\theta } = m a _ { \\\\theta }'],\n",
       " ['train_00016.jpg',\n",
       "  '= \\\\frac { \\\\left( n + 2 \\\\right) \\\\left( n + 1 \\\\right) } { 2 } = 7 8 = 2 \\\\times 3 9 = 2 \\\\times 3 \\\\times 1 3'],\n",
       " ['train_00017.jpg', '= h \\\\left( a \\\\right)'],\n",
       " ['train_00018.jpg',\n",
       "  '1 0 4 \\\\times 9 8 = \\\\left( 1 0 0 + 4 \\\\right) \\\\left( 1 0 0 - 2 \\\\right)'],\n",
       " ['train_00019.jpg', 'a _ { n } = a _ { 1 } r ^ { n - 1 }'],\n",
       " ['train_00020.jpg', 'x = - 2'],\n",
       " ['train_00021.jpg', '= 3 x \\\\left( x ^ { 2 } + 1 \\\\right)'],\n",
       " ['train_00022.jpg', '1 8 4 - \\\\left( 8 9 + 8 8 \\\\right) = 7'],\n",
       " ['train_00023.jpg', 't = - 1'],\n",
       " ['train_00024.jpg',\n",
       "  '\\\\left( 1 2 x - 1 6 \\\\right) \\\\times \\\\left( - \\\\frac { 3 } { 4 } \\\\right) = 1 2 x \\\\times \\\\left( - \\\\frac { 3 } { 4 } \\\\right)'],\n",
       " ['train_00025.jpg', '\\\\frac { 1 6 } { 2 7 } \\\\div \\\\frac { 2 } { 2 7 } ='],\n",
       " ['train_00026.jpg', 'x < 4'],\n",
       " ['train_00027.jpg',\n",
       "  '= x \\\\left( x - 1 \\\\right) \\\\cdot \\\\left( x - 2 \\\\right) !'],\n",
       " ['train_00028.jpg', '3 6 . 4 8 \\\\div 4 , 5 6'],\n",
       " ['train_00029.jpg',\n",
       "  'a = \\\\sqrt { a _ { r } ^ { 2 } + a _ { \\\\theta } ^ { 2 } } = \\\\sqrt { \\\\left( 0 . 3 3 6 \\\\right) ^ { 2 } + \\\\left( 0 . 0 7 \\\\right) ^ { 2 } } = 0 . 3 4 m / s'],\n",
       " ['train_00030.jpg',\n",
       "  'P \\\\left( A \\\\right) \\\\cdot P \\\\left( B \\\\right) = \\\\frac { 1 } { 2 } \\\\times \\\\frac { 1 } { 2 } = \\\\frac { 1 } { 4 } \\\\neq \\\\left( A \\\\cap B \\\\right)'],\n",
       " ['train_00031.jpg',\n",
       "  'x = \\\\frac { - b ^ \\\\prime \\\\pm \\\\sqrt { b ^ \\\\prime - a c } } { a }']]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6857a8-20c9-4525-82c9-ce8135e32a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
