{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0f4e36-70ba-4ced-b426-e77a1070c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from train import id_to_string\n",
    "from metrics import word_error_rate, sentence_acc\n",
    "from checkpoint import load_checkpoint\n",
    "from torchvision import transforms\n",
    "from dataset import LoadEvalDataset, collate_eval_batch, START, PAD\n",
    "from flags import Flags\n",
    "from utils import get_network, get_optimizer\n",
    "import csv\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab280699-a141-44c8-8f7b-5046aa69efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "from dataset import START, PAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee37896-5ef2-4ac5-8f61-8443a37f39ce",
   "metadata": {},
   "source": [
    "- \"--checkpoint\" 에 불러올 .pth 파일 주소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94f93277-be24-45d1-ac27-cb69cce20609",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "        \"--checkpoint1\",\n",
    "        dest=\"checkpoint1\",\n",
    "        default=\"./log/ensemble/checkpoints/0034.pth\",\n",
    "        type=str,\n",
    "        help=\"Path of checkpoint file\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "        \"--checkpoint2\",\n",
    "        dest=\"checkpoint2\",\n",
    "        default=\"./log/ensemble/checkpoints/0035.pth\",\n",
    "        type=str,\n",
    "        help=\"Path of checkpoint file\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "        \"--checkpoint3\",\n",
    "        dest=\"checkpoint3\",\n",
    "        default=\"./log/ensemble/checkpoints/0036.pth\",\n",
    "        type=str,\n",
    "        help=\"Path of checkpoint file\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "        \"--max_sequence\",\n",
    "        dest=\"max_sequence\",\n",
    "        default=20,\n",
    "        type=int,\n",
    "        help=\"maximun sequence when doing inference\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        dest=\"batch_size\",\n",
    "        default=1,\n",
    "        type=int,\n",
    "        help=\"batch size when doing inference\",\n",
    ")\n",
    "\n",
    "eval_dir = os.environ.get('SM_CHANNEL_EVAL', '/opt/ml/input/data/')\n",
    "file_path = os.path.join(eval_dir, 'eval_dataset/input.txt')\n",
    "parser.add_argument(\n",
    "        \"--file_path\",\n",
    "        dest=\"file_path\",\n",
    "        default=file_path,\n",
    "        type=str,\n",
    "        help=\"file path when doing inference\",\n",
    ")\n",
    "\n",
    "output_dir = os.environ.get('SM_OUTPUT_DATA_DIR', 'submit')\n",
    "parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        dest=\"output_dir\",\n",
    "        default=output_dir,\n",
    "        type=str,\n",
    "        help=\"output directory\",\n",
    ")\n",
    "\n",
    "parser = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f88b42d-fad8-425c-b5d8-85aeb53481db",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "checkpoint1 = load_checkpoint(parser.checkpoint1, cuda=is_cuda)\n",
    "checkpoint2 = load_checkpoint(parser.checkpoint2, cuda=is_cuda)\n",
    "checkpoint3 = load_checkpoint(parser.checkpoint3, cuda=is_cuda)\n",
    "options1 = Flags(checkpoint1[\"configs\"]).get()\n",
    "options2 = Flags(checkpoint2[\"configs\"]).get()\n",
    "options3 = Flags(checkpoint3[\"configs\"]).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dfbb36f-925a-4423-aba2-1c85a3cd528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(options1.seed)\n",
    "random.seed(options1.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3decc9d4-31fc-4921-8ff6-b4a847daf98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Running SATRN on device cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hardware = \"cuda\" if is_cuda else \"cpu\"\n",
    "device = torch.device(hardware)\n",
    "print(\"--------------------------------\")\n",
    "print(\"Running {} on device {}\\n\".format(options1.network, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe6171e4-4bd0-48da-9275-4557f48afad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Checkpoint\n",
      " Resuming from epoch : 34\n",
      "\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint1 = checkpoint1[\"model\"]\n",
    "if model_checkpoint1:\n",
    "        print(\n",
    "            \"[+] Checkpoint\\n\",\n",
    "            \"Resuming from epoch : {}\\n\".format(checkpoint1[\"epoch\"]),\n",
    "        )\n",
    "print(options1.input_size.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c96cb55f-1397-4f11-bf99-82ca3ab19871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Checkpoint\n",
      " Resuming from epoch : 35\n",
      "\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint2 = checkpoint2[\"model\"]\n",
    "if model_checkpoint2:\n",
    "        print(\n",
    "            \"[+] Checkpoint\\n\",\n",
    "            \"Resuming from epoch : {}\\n\".format(checkpoint2[\"epoch\"]),\n",
    "        )\n",
    "print(options2.input_size.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d718780f-db01-44ec-bb98-94c5bd64043b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Checkpoint\n",
      " Resuming from epoch : 35\n",
      "\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint3 = checkpoint3[\"model\"]\n",
    "if model_checkpoint3:\n",
    "        print(\n",
    "            \"[+] Checkpoint\\n\",\n",
    "            \"Resuming from epoch : {}\\n\".format(checkpoint3[\"epoch\"]),\n",
    "        )\n",
    "print(options3.input_size.height)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024a5693-0ca9-4729-b955-6ce33e244f08",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3ca70c0-4f5d-4d94-9a49-6de706325f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Data\n",
      " The number of test samples : 32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((options1.input_size.height, options1.input_size.width)),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "dummy_gt = \"\\sin \" * parser.max_sequence  # set maximum inference sequence\n",
    "\n",
    "root = os.path.join(os.path.dirname(parser.file_path), \"images\")\n",
    "with open(parser.file_path, \"r\") as fd:\n",
    "    reader = csv.reader(fd, delimiter=\"\\t\")\n",
    "    data = list(reader)\n",
    "test_data = [[os.path.join(root, x[0]), x[0], dummy_gt] for x in data]\n",
    "test_dataset = LoadEvalDataset(\n",
    "    test_data, checkpoint1[\"token_to_id\"], checkpoint1[\"id_to_token\"], crop=False, transform=transformed,\n",
    "    rgb=options1.data.rgb\n",
    ")\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=parser.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=options1.num_workers,\n",
    "        collate_fn=collate_eval_batch,\n",
    ")\n",
    "\n",
    "print(\n",
    "        \"[+] Data\\n\",\n",
    "        \"The number of test samples : {}\\n\".format(len(test_dataset)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c6cc7-1a87-4169-95cf-2c9bf8f69b96",
   "metadata": {},
   "source": [
    "### Get Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fce68ec-05dc-45b3-9479-7a1735345e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = get_network(\n",
    "        options1.network,\n",
    "        options1,\n",
    "        model_checkpoint1,\n",
    "        device,\n",
    "        test_dataset,\n",
    "    )\n",
    "model1.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b573a1fc-7d6c-4fc0-966b-6fbeadf80ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = model1.encoder\n",
    "embedding1 = model1.decoder.embedding\n",
    "pos_encoder1 = model1.decoder.pos_encoder\n",
    "attention_layers1 = model1.decoder.attention_layers\n",
    "generator1 = model1.decoder.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a79e89d0-d976-4c31-a6af-21a9b50a530d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = get_network(\n",
    "        options2.network,\n",
    "        options2,\n",
    "        model_checkpoint2,\n",
    "        device,\n",
    "        test_dataset,\n",
    "    )\n",
    "model2.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2218f3c9-f6f8-4feb-a8a4-455d7e48f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder2 = model2.encoder\n",
    "embedding2 = model2.decoder.embedding\n",
    "pos_encoder2 = model2.decoder.pos_encoder\n",
    "attention_layers2 = model2.decoder.attention_layers\n",
    "generator2 = model2.decoder.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6b548b0-5477-478f-b6dc-465c41ed50ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model3 = get_network(\n",
    "        options3.network,\n",
    "        options3,\n",
    "        model_checkpoint3,\n",
    "        device,\n",
    "        test_dataset,\n",
    "    )\n",
    "model3.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eb5eb71-99b1-4b06-8431-ea164892e382",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder3 = model3.encoder\n",
    "embedding3 = model3.decoder.embedding\n",
    "pos_encoder3 = model3.decoder.pos_encoder\n",
    "attention_layers3 = model3.decoder.attention_layers\n",
    "generator3 = model3.decoder.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f649cc33-7401-4675-91d2-12650b4be9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_id = test_dataset.token_to_id['<SOS>']\n",
    "pad_id = test_dataset.token_to_id['<PAD>']\n",
    "layer_num = len(model1.decoder.attention_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2851be64-5152-49e7-9857-63ed5445a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_mask(text):\n",
    "        pad_mask = text == pad_id\n",
    "        pad_mask[:, 0] = False\n",
    "        pad_mask = pad_mask.unsqueeze(1)\n",
    "\n",
    "        return pad_mask\n",
    "\n",
    "def order_mask(length):\n",
    "        order_mask = torch.triu(torch.ones(length, length), diagonal=1).bool()\n",
    "        order_mask = order_mask.unsqueeze(0).to(device)\n",
    "        return order_mask\n",
    "\n",
    "def text_embedding1(texts):\n",
    "        tgt = embedding1(texts)\n",
    "        tgt *= math.sqrt(tgt.size(2))\n",
    "\n",
    "        return tgt\n",
    "    \n",
    "def text_embedding2(texts):\n",
    "        tgt = embedding2(texts)\n",
    "        tgt *= math.sqrt(tgt.size(2))\n",
    "\n",
    "        return tgt\n",
    "\n",
    "def text_embedding3(texts):\n",
    "        tgt = embedding3(texts)\n",
    "        tgt *= math.sqrt(tgt.size(2))\n",
    "\n",
    "        return tgt    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321290ce-8139-458f-a54c-3f31df0b7221",
   "metadata": {},
   "source": [
    "### Ensemble Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80e7f218-1f86-4b10-9a39-8236c1445537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:52<00:00,  5.45s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for d in tqdm(test_data_loader):\n",
    "    input = d[\"image\"].to(device)\n",
    "    expected = d[\"truth\"][\"encoded\"].to(device)\n",
    "    \n",
    "    src1 = encoder1(input)\n",
    "    src2 = encoder2(input)\n",
    "    src3 = encoder3(input)\n",
    "    \n",
    "    text = expected[:, :-1]\n",
    "    is_train = False\n",
    "    batch_max_length = 230\n",
    "    teacher_forcing_ratio = 0\n",
    "    \n",
    "    out = []\n",
    "    num_steps = batch_max_length - 1\n",
    "    target = torch.LongTensor(src1.size(0)).fill_(st_id).to(device) # [START] token\n",
    "    features = [None] * layer_num\n",
    "    \n",
    "    features1 = []\n",
    "    features2 = []\n",
    "    features3 = []\n",
    "    if features[0] != None:\n",
    "        for i in range(len(features)):\n",
    "            features1.append(copy.deepcopy(features[i].detach()))\n",
    "    \n",
    "        for i in range(len(features)):\n",
    "            features2.append(copy.deepcopy(features[i].detach()))\n",
    "            \n",
    "        for i in range(len(features)):\n",
    "            features3.append(copy.deepcopy(features[i].detach()))\n",
    "            \n",
    "    else:\n",
    "        features1 = [None] * layer_num\n",
    "        features2 = [None] * layer_num\n",
    "        features3 = [None] * layer_num\n",
    "        \n",
    "    \n",
    "    for t in range(num_steps):\n",
    "        target = target.unsqueeze(1)\n",
    "        tgt1 = text_embedding1(target)\n",
    "        tgt2 = text_embedding2(target)\n",
    "        tgt3 = text_embedding3(target)\n",
    "        \n",
    "        tgt1 = pos_encoder1(tgt1, point=t)\n",
    "        tgt2 = pos_encoder2(tgt2, point=t)\n",
    "        tgt3 = pos_encoder3(tgt3, point=t)\n",
    "        \n",
    "        tgt_mask = order_mask(t + 1).to(device)\n",
    "        tgt_mask = tgt_mask[:, -1].unsqueeze(1)  # [1, (l+1)]\n",
    "        \n",
    "        for l, layer in enumerate(zip(attention_layers1, attention_layers2, attention_layers3)):\n",
    "            tgt1 = layer[0](tgt1, features[l], src1, tgt_mask)\n",
    "            features1[l] = (\n",
    "                tgt1 if features1[l] == None else torch.cat([features1[l], tgt1], 1)\n",
    "            )\n",
    "            \n",
    "            tgt2 = layer[1](tgt2, features[l], src2, tgt_mask)\n",
    "            features2[l] = (\n",
    "                tgt2 if features2[l] == None else torch.cat([features2[l], tgt2], 1)\n",
    "            )\n",
    "            \n",
    "            tgt3 = layer[1](tgt3, features[l], src3, tgt_mask)\n",
    "            features3[l] = (\n",
    "                tgt3 if features3[l] == None else torch.cat([features3[l], tgt3], 1)\n",
    "            )\n",
    "        \n",
    "        for i in range(len(features)):\n",
    "            features[i] = (features1[i] + features2[i] + features3[i]) / 3\n",
    "            \n",
    "        _out1 = generator1(tgt1)  # [b, 1, c]\n",
    "        _out2 = generator2(tgt2)  # [b, 1, c]\n",
    "        _out3 = generator2(tgt3)  # [b, 1, c]\n",
    "        \n",
    "        _out = _out1 + _out2 + _out3\n",
    "        \n",
    "        target = torch.argmax(_out[:, -1:, :], dim=-1)  # [b, 1]\n",
    "        target = target.squeeze(1)   # [b]\n",
    "        out.append(_out)\n",
    "        \n",
    "    out = torch.stack(out, dim=1).to(device)    # [b, max length, 1, class length]\n",
    "    out = out.squeeze(2)    # [b, max length, class length]\n",
    "    \n",
    "    decoded_values = out.transpose(1, 2)\n",
    "    _, sequence = torch.topk(decoded_values, 1, dim=1)\n",
    "    sequence = sequence.squeeze(1)\n",
    "    sequence_str = id_to_string(sequence, test_data_loader, do_eval=1)\n",
    "    \n",
    "    for path, predicted in zip(d[\"file_path\"], sequence_str):\n",
    "        results.append((path, predicted))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0cd8f59-917e-40a0-944a-ddd26c3944a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(parser.output_dir, exist_ok=True)\n",
    "with open(os.path.join(parser.output_dir, \"output_ensemble.csv\"), \"w\") as w:\n",
    "    for path, predicted in results:\n",
    "        w.write(path + \"\\t\" + predicted + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e2582-185a-42a5-92a8-da5ce727bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7677af7-b984-42b5-94f7-1a566110fdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['train_00000.jpg', '4 \\\\times 7 = 2 8'],\n",
       " ['train_00001.jpg', 'a ^ { x } > q'],\n",
       " ['train_00002.jpg', '8 \\\\times 9'],\n",
       " ['train_00003.jpg',\n",
       "  '\\\\sum _ { k = 1 } ^ { n - 1 } b _ { k } = a _ { n } - a _ { 1 }'],\n",
       " ['train_00004.jpg', 'I = d q / d t'],\n",
       " ['train_00005.jpg', '\\\\sum \\\\overrightarrow { F } _ { e x t } = d'],\n",
       " ['train_00006.jpg', 'i ^ { 2 } = - 1 \\\\left( i = \\\\sqrt { - 1 } \\\\right)'],\n",
       " ['train_00007.jpg', '7 \\\\times 9 = 4 9'],\n",
       " ['train_00008.jpg',\n",
       "  'F \\\\left( 0 , \\\\sqrt { a ^ { 2 } + b ^ { 2 } } \\\\right) , \\\\left( 0 , - \\\\sqrt { a ^ { 2 } + b ^ { 2 } } \\\\right)'],\n",
       " ['train_00009.jpg', '\\\\left( a - 2 \\\\right) \\\\left( a - 3 \\\\right) = 0'],\n",
       " ['train_00010.jpg', '\\\\therefore b = - 9'],\n",
       " ['train_00011.jpg', '2 2 + 7 - 1 2 ='],\n",
       " ['train_00012.jpg', '7 \\\\div 4'],\n",
       " ['train_00013.jpg', 'f \\\\left( x \\\\right) = 4 x ^ { 3 }'],\n",
       " ['train_00014.jpg',\n",
       "  'M P _ { e } = \\\\lim _ { \\\\Delta l \\\\to 0 } \\\\frac { g \\\\left( l + \\\\Delta l \\\\right) - g \\\\left( l \\\\right) } { \\\\Delta l } = \\\\frac { d g } { d l }'],\n",
       " ['train_00015.jpg', '\\\\sum F _ { \\\\theta } = m a _ { \\\\theta }'],\n",
       " ['train_00016.jpg',\n",
       "  '= \\\\frac { \\\\left( n + 2 \\\\right) \\\\left( n + 1 \\\\right) } { 2 } = 7 8 = 2 \\\\times 3 9 = 2 \\\\times 3 \\\\times 1 3'],\n",
       " ['train_00017.jpg', '= h \\\\left( a \\\\right)'],\n",
       " ['train_00018.jpg',\n",
       "  '1 0 4 \\\\times 9 8 = \\\\left( 1 0 0 + 4 \\\\right) \\\\left( 1 0 0 - 2 \\\\right)'],\n",
       " ['train_00019.jpg', 'a _ { n } = a _ { 1 } r ^ { n - 1 }'],\n",
       " ['train_00020.jpg', 'x = - 2'],\n",
       " ['train_00021.jpg', '= 3 x \\\\left( x ^ { 2 } + 1 \\\\right)'],\n",
       " ['train_00022.jpg', '1 8 4 - \\\\left( 8 9 + 8 8 \\\\right) = 7'],\n",
       " ['train_00023.jpg', 't = - 1'],\n",
       " ['train_00024.jpg',\n",
       "  '\\\\left( 1 2 x - 1 6 \\\\right) \\\\times \\\\left( - \\\\frac { 3 } { 4 } \\\\right) = 1 2 x \\\\times \\\\left( - \\\\frac { 3 } { 4 } \\\\right)'],\n",
       " ['train_00025.jpg', '\\\\frac { 1 6 } { 2 7 } \\\\div \\\\frac { 2 } { 2 7 } ='],\n",
       " ['train_00026.jpg', 'x < 4'],\n",
       " ['train_00027.jpg',\n",
       "  '= x \\\\left( x - 1 \\\\right) \\\\cdot \\\\left( x - 2 \\\\right) !'],\n",
       " ['train_00028.jpg', '3 6 . 4 8 \\\\div 4 , 5 6'],\n",
       " ['train_00029.jpg',\n",
       "  'a = \\\\sqrt { a _ { r } ^ { 2 } + a _ { \\\\theta } ^ { 2 } } = \\\\sqrt { \\\\left( 0 . 3 3 6 \\\\right) ^ { 2 } + \\\\left( 0 . 0 7 \\\\right) ^ { 2 } } = 0 . 3 4 m / s'],\n",
       " ['train_00030.jpg',\n",
       "  'P \\\\left( A \\\\right) \\\\cdot P \\\\left( B \\\\right) = \\\\frac { 1 } { 2 } \\\\times \\\\frac { 1 } { 2 } = \\\\frac { 1 } { 4 } \\\\neq \\\\left( A \\\\cap B \\\\right)'],\n",
       " ['train_00031.jpg',\n",
       "  'x = \\\\frac { - b ^ \\\\prime \\\\pm \\\\sqrt { b ^ \\\\prime - a c } } { a }']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0c92c0-efa5-42d4-81d2-1839b0155a88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
